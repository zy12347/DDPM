{"cells":[{"cell_type":"code","execution_count":3,"id":"1f1c5486","metadata":{"id":"1f1c5486","executionInfo":{"status":"ok","timestamp":1681841903385,"user_tz":240,"elapsed":5673,"user":{"displayName":"Phillip Bridges","userId":"14924419059045601452"}}},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import numpy as np\n","import scipy\n","from torchvision import datasets, models, transforms\n","from torchvision.utils import save_image\n","import torchvision\n","import torch.utils.data\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","from drive.MyDrive.Colab_Notebooks.Diffuse_553.ddpm_553.utils import *\n","from drive.MyDrive.Colab_Notebooks.Diffuse_553.ddpm_553.UNet import UNet\n","import logging\n","from torch.utils.tensorboard import SummaryWriter\n","logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%I:%M:%S\")"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"vq02PSh7UIsn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681841897714,"user_tz":240,"elapsed":14733,"user":{"displayName":"Phillip Bridges","userId":"14924419059045601452"}},"outputId":"640b592b-1088-4a8c-ae7a-120a7b0c44a2"},"id":"vq02PSh7UIsn","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install pytorch_fid"],"metadata":{"id":"HBh5fU8lTHN3"},"id":"HBh5fU8lTHN3","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import argparse\n","parser = argparse.ArgumentParser()\n","args = parser.parse_known_args()[0]\n","args.run_name = \"DDPM_Uncondtional\"\n","args.epochs = 5\n","args.batch_size = 128\n","args.image_size = 32\n","args.dataset_path = \"./drive/MyDrive/Colab_Notebooks/Diffuse_553/ddpm_553/datasets\"\n","args.subset_path = \"./drive/MyDrive/Colab_Notebooks/Diffuse_553/ddpm_553/datasets/cifar10_subset_images\"\n","args.device = \"cuda\"\n","args.lr = 3e-4\n","args.loss_type = 'mse'  # 'mse' or 'l1'"],"metadata":{"id":"aQAUL5QdO1b5"},"id":"aQAUL5QdO1b5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get cifar_10 data\n","def get_data_cifar10(args):\n","    transforms = torchvision.transforms.Compose([\n","        #torchvision.transforms.Resize(40),  # args.image_size + 1/4 *args.image_size\n","        #torchvision.transforms.RandomResizedCrop(args.image_size, scale=(0.8, 1.0)),\n","        torchvision.transforms.RandomHorizontalFlip(),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])\n","    #dataset = torchvision.datasets.ImageFolder(args.dataset_path, transform=transforms)\n","    dataset_un = torchvision.datasets.CIFAR10(root= args.dataset_path,train=True, transform=transforms, download=False)\n","    dataloader = DataLoader(dataset_un, batch_size=args.batch_size, shuffle=True)\n","    return dataloader, dataset_un"],"metadata":{"id":"Fpra0mxqObYh"},"id":"Fpra0mxqObYh","execution_count":null,"outputs":[]},{"cell_type":"code","source":["torchvision.datasets.Flowers102(\"./\",download=True)"],"metadata":{"id":"Xbh0ZC1hm7Qq"},"id":"Xbh0ZC1hm7Qq","execution_count":null,"outputs":[]},{"cell_type":"code","source":["## -------------run only for the first time !!---------------\n","\n","# Create the directory for CIFAR10 subset images\n","os.makedirs('./drive/MyDrive/Colab_Notebooks/Diffuse_553/ddpm_553/datasets/cifar10_subset_images', exist_ok=True)\n","\n","# Create the directory for CIFAR10 generated images\n","os.makedirs('./drive/MyDrive/Colab_Notebooks/Diffuse_553/ddpm_553/datasets/cifar10_generate_images', exist_ok=True)\n","\n","# generate a subset of cifar_10\n","dataloader, dataset_un = get_data_cifar10(args)\n","n = 10000  # create subset \n","cifar10_subset, _ = torch.utils.data.random_split(dataset_un, [n,len(dataset_un)-n])\n","cifar10_subset_dataloader_un = DataLoader(cifar10_subset, batch_size=args.batch_size, shuffle=True)\n","\n","#save images to path\n","for i, (image, _) in enumerate(cifar10_subset):\n","    save_image(image,f'./drive/MyDrive/Colab_Notebooks/Diffuse_553/ddpm_553/datasets/cifar10_subset_images/image_{i}.png')\n"],"metadata":{"id":"nUEd3OVqOYFo"},"id":"nUEd3OVqOYFo","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"4d603cce","metadata":{"id":"4d603cce"},"outputs":[],"source":["class Diffusion:\n","    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=256, device=\"cuda\"):\n","        self.noise_steps = noise_steps\n","        self.beta_start = beta_start\n","        self.beta_end = beta_end\n","        self.img_size = img_size\n","        self.device = device\n","        self.beta = self.prepare_noise_schedule().to(device)\n","        self.alpha = 1. - self.beta\n","        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n","\n","    def prepare_noise_schedule(self, use_cosine=False, s=0.008):  \n","        if use_cosine == True:\n","            def f(t, noise_steps):\n","                return (np.cos((t / noise_steps + s) / (1 + s) * np.pi / 2)) ** 2\n","            alphas = []\n","            f0 = f(0, self.noise_steps)\n","            for t in range(self.noise_steps + 1):\n","                alphas.append(f(t, self.noise_steps) / f0)\n","            betas = []\n","            for t in range(1, self.noise_steps + 1):\n","                betas.append(min(1 - alphas[t] / alphas[t - 1], 0.999))\n","            return torch.tensor(betas)\n","        else:\n","            return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n","\n","    def noise_images(self, x, t):\n","        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n","        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n","        Ɛ = torch.randn_like(x)\n","        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Ɛ, Ɛ\n","\n","    def sample_timesteps(self, n):\n","        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n","\n","    def sample(self, model, n):\n","        logging.info(f\"Sampling {n} new images....\")\n","        model.eval()\n","        with torch.no_grad():\n","            x = torch.randn((n, 3, self.img_size, self.img_size)).to(self.device)\n","            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n","                t = (torch.ones(n) * i).long().to(self.device)\n","                predicted_noise = model(x, t)\n","                alpha = self.alpha[t][:, None, None, None]\n","                alpha_hat = self.alpha_hat[t][:, None, None, None]\n","                beta = self.beta[t][:, None, None, None]\n","                if i > 1:\n","                    noise = torch.randn_like(x)\n","                else:\n","                    noise = torch.zeros_like(x)\n","                x = 1 / torch.sqrt(alpha) * (x - (beta / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n","        model.train()\n","        x = (x.clamp(-1, 1) + 1) / 2\n","        x = (x * 255).type(torch.uint8)\n","        return x"]},{"cell_type":"code","source":["#print('# of samples for ulabeled, train, and test, {}'.format(len(dataset_un)))\n","#print('Classes in train: {}'.format(dataset_un.classes))"],"metadata":{"id":"3NgvoBhhhvu_"},"id":"3NgvoBhhhvu_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataloader, dataset_un = get_data_cifar10(args)\n","n = 10000  # create subset \n","cifar10_subset, _ = torch.utils.data.random_split(dataset_un, [n,len(dataset_un)-n])\n","cifar10_subset_dataloader_un = DataLoader(cifar10_subset, batch_size=args.batch_size, shuffle=True)"],"metadata":{"id":"uUavLVNGbUUU"},"id":"uUavLVNGbUUU","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"55f32481","metadata":{"id":"55f32481"},"outputs":[],"source":["def train(args):\n","    setup_logging(args.run_name)\n","    device = args.device\n","    model = UNet().to(device)\n","    if os.path.exists(\"./drive/MyDrive/Colab_Notebooks/Diffuse_553/ddpm_553/models/DDPM_Uncondtional/uncondition_ckpt_large_cifar.pt\"):\n","        ckpt = torch.load(\"./drive/MyDrive/Colab_Notebooks/Diffuse_553/ddpm_553/models/DDPM_Uncondtional/uncondition_ckpt_large_cifar.pt\")\n","        model.load_state_dict(ckpt)\n","    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n","    if args.loss_type == 'mse':\n","        unet_loss = nn.MSELoss()\n","    elif args.loss_type == 'l1':\n","        unet_loss = nn.L1loss()\n","    diffusion = Diffusion(img_size=args.image_size, device=device)\n","    logger = SummaryWriter(os.path.join(\"runs\", args.run_name))\n","    l = len(cifar10_subset_dataloader_un)\n","\n","    for epoch in range(args.epochs):\n","        logging.info(f\"Starting epoch {epoch}:\")\n","        pbar = tqdm(cifar10_subset_dataloader_un)\n","        for i, (images, _) in enumerate(pbar):\n","            images = images.to(device)\n","            t = diffusion.sample_timesteps(images.shape[0]).to(device)\n","            x_t, noise = diffusion.noise_images(images, t)\n","            predicted_noise = model(x_t, t)\n","            loss = unet_loss(noise, predicted_noise)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            if args.loss_type == 'mse':\n","                pbar.set_postfix(MSE=loss.item())\n","                logger.add_scalar(\"MSE\", loss.item(), global_step=epoch * l + i)\n","            elif args.loss_type == 'l1': \n","                pbar.set_postfix(L1=loss.item())\n","                logger.add_scalar(\"L1\", loss.item(), global_step=epoch * l + i)\n","\n","        sampled_images = diffusion.sample(model, n=images.shape[0])\n","        save_images(sampled_images, os.path.join(\"./drive/MyDrive/Colab_Notebooks/Diffuse_553/ddpm_553/results\", args.run_name, f\"{150+epoch}.jpg\"))\n","        torch.save(model.state_dict(), os.path.join(\"./drive/MyDrive/Colab_Notebooks/Diffuse_553/ddpm_553/models\", args.run_name, f\"uncondition_ckpt_large_cifar.pt\"))\n"]},{"cell_type":"code","source":["if os.path.exists(\"./drive/MyDrive/Colab_Notebooks/Diffuse_553/ddpm_553/models/DDPM_Uncondtional/uncondition_ckpt_large_cifar.pt\"):\n","  print(\"1\")"],"metadata":{"id":"mXwzZfkZWOa2"},"id":"mXwzZfkZWOa2","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"89a016d9","metadata":{"scrolled":true,"id":"89a016d9"},"outputs":[],"source":["if __name__ == '__main__':\n","    train(args)"]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"h30ghMQLbWBB"},"id":"h30ghMQLbWBB","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"3040cc5a","metadata":{"id":"3040cc5a"},"outputs":[],"source":["sample_number = 400\n","device = \"cuda\"\n","model = UNet().to(device)\n","ckpt = torch.load(\"./drive/MyDrive/Colab_Notebooks/Diffuse_553/ddpm_553/models/DDPM_Uncondtional/uncondition_ckpt_large_cifar.pt\")\n","model.load_state_dict(ckpt)\n","diffusion = Diffusion(img_size=32, device=device)\n","sampled_images = diffusion.sample(model, sample_number)\n","print(sampled_images.shape)    \n","#plt.figure(figsize=(16, 16))\n","#plt.imshow(torch.cat([torch.cat([i for i in sampled_images.cpu()], dim=-1)], dim=-2).permute(1, 2, 0).cpu())\n","#plt.show()"]},{"cell_type":"code","source":["# Define the number of rows and columns for the plot\n","num_rows = sample_number//8\n","num_cols = 8\n","\n","# Split the generated images into rows\n","image_rows = [sampled_images[i:i+num_cols] for i in range(0, len(sampled_images), num_cols)]\n","\n","# Concatenate the images within each row horizontally\n","concatenated_rows = [torch.cat(tuple(image_row), dim=-1) for image_row in image_rows]\n","\n","# Concatenate the rows vertically\n","concatenated_image = torch.cat(tuple(concatenated_rows), dim=-2)\n","\n","# Plot the concatenated image\n","plt.figure(figsize=(10, 8))\n","plt.imshow(concatenated_image.permute(1, 2, 0).cpu())\n","plt.axis('off')\n","plt.show()\n","\n"],"metadata":{"id":"oeN8RowIl6yy"},"id":"oeN8RowIl6yy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pytorch_fid import fid_score\n","\n","cifar10_subset_path = './drive/MyDrive/Colab_Notebooks/Diffuse_553/ddpm_553/datasets/cifar10_subset_images'\n","generated_images_path = './drive/MyDrive/Colab_Notebooks/Diffuse_553/ddpm_553/datasets/cifar10_generate_images'\n","\n","# Save the generated images to disk \n","for i in range(sample_number):\n","    # Ensure that the pixel values are in the range [0, 1]\n","    sampled_image = sampled_images[i].float()/255.0\n","    save_image(sampled_image, f'./drive/MyDrive/Colab_Notebooks/Diffuse_553/ddpm_553/datasets/cifar10_generate_images/image_{i}.png')\n"],"metadata":{"id":"KihxRZGiH8Y8"},"id":"KihxRZGiH8Y8","execution_count":null,"outputs":[]},{"cell_type":"code","source":["fid = fid_score.calculate_fid_given_paths([cifar10_subset_path, generated_images_path], 128, 'cuda',2048)\n","print('FID score:', fid)"],"metadata":{"id":"Dc4QBkRR1mN6"},"id":"Dc4QBkRR1mN6","execution_count":null,"outputs":[]}],"metadata":{"@webio":{"lastCommId":null,"lastKernelId":null},"kernelspec":{"display_name":"Pytorch","language":"python","name":"pytorch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}